import streamlit as st
from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
import numpy as np


# -----------------------------------------------------------------------------
# MODEL LOADING
# -----------------------------------------------------------------------------
@st.cache_resource
def load_caption_model():
    # TODO: Load the Processor (Handles image resizing & tokenization)
    processor = BlipProcessor.from_pretrained('Salesforce/blip-image-captioning-base')
    
    # TODO: Load the Model 
    model = BlipForConditionalGeneration.from_pretrained('Salesforce/blip-image-captioning-base')
    return processor, model

processor, model = load_caption_model()

# -----------------------------------------------------------------------------
# UI LAYOUT
# -----------------------------------------------------------------------------
# set title and sidebar
st.title("üé® The Image Captioner")
# set sidebar sliders
st.sidebar.subheader("‚öôÔ∏è Parameter Settings")
# 1. Temperature (min_value=0.1, max_value=1.5, value=0.1, step=0.1)
temperature = st.sidebar.slider(
    "Temperature",
    min_value=0.1, 
    max_value=1.5, 
    value=0.1,
    step=0.1, 
    help="Temperature is a key AI parameter that controls how creative or predictable an AI model's outputs will be, determining whether responses stick close to proven patterns or explore more varied possibilities.")
# 2. Max Length (min_value=5, max_value=30, value=20, step=1)
max_length = st.sidebar.slider(
    "Max Length (Tokens)",
    min_value=5, 
    max_value=30, 
    value=20, 
    step=1, 
    help="The max number of new tokens that should be generated by the model.")
# 3. Min Length (min_value=3, max_value=20, value=5, step=1)
min_length = st.sidebar.slider(
    "Min Length (Tokens)",
    min_value=3, 
    max_value=20, 
    value=5, 
    step=1, 
    help="The min number of new tokens that should be generated by the model.")
# 4. Number of Variations (min_value=1, max_value=5, value=1, step=1)
num_captions = st.sidebar.slider(
    "Number of Variations",
    min_value=1, 
    max_value=5, 
    value=1, 
    step=1, 
    help="How many variation (version) of caption should be generated by the model.")
# -----------------------------------------------------------------------------
# MAIN PIPELINE
# -----------------------------------------------------------------------------
# Introduction text under title
st.write("Transform your visuals into descriptive text instantly. " \
"This tool leverages advanced vision models to analyze your images and generate accurate, " \
"context-aware captions based on your custom parameters.")

# File uploader for images, accept jpg, jpeg, png

uploaded_file = st.file_uploader("Choose an image...", type=["jpg","jpeg","png"], accept_multiple_files=False)

if uploaded_file is not None:
    # If an image is uploaded, display it
    image = Image.open(uploaded_file)
    st.image(image, caption="Uploaded image")

    # Create a input box for starting text prompt
    col1 , col2 = st.columns([1,2])
    with col1:
         st.write("Starting sentence:")
    with col2: 
        start_text = st.text_input(label="text",label_visibility="collapsed",placeholder="e.g. 'A photo of a funny...'")

    # # Create a button called 'Generate Caption' to trigger the AI
    if st.button("Generate Caption:"):
        # You may add a loading spinner here while the model is generating captions
            
            # Display a subheader 'Caption(s):'
            st.subheader("Caption(s):")
            # PRE-PROCESSING (Convert Image & Text to Tensors) ---
            # If user provided start_text, we pass it as 'text'. 
            # Otherwise we just pass the image.
            if start_text:
                inputs = processor(images=image, text=start_text ,return_tensors="pt")
            else:
                inputs = processor(images=image, return_tensors="pt")
            
            # Create a loop that runs 'num_captions' times
            with st.spinner("Captions are being generated...", show_time=True):
                for i in range(num_captions):
                    # Pass the inputs and parameters to generate caption(s).
                    # Some parameters are already given.
                    # It should also contain the parameter values given by the user via the sliders.
                    out = model.generate(
                        **inputs,
                        do_sample=True,             
                        temperature = temperature,
                        max_length=max_length,
                        min_length=min_length,
                        top_k=50
                    )

                    # POST-PROCESSING (Decode Tensors back to Text)
                    # The model gives us numbers, we need to decode them to words.               
                    caption_text = processor.decode(out[0], skip_special_tokens=True)
                
                    # Display the result(s) depending on number of variations.
                    st.success(caption_text)